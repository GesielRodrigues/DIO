{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Bootcamp Microsoft Certification Challenge #1 - AI 102](https://assets.dio.me/79IKKjY5EHRPqlscNsYum7Iv9uQNa_siSO7Ab8Zv3II/f:webp/h:120/q:80/L3RyYWNrcy8wMzI1ZTE2Ni1mYTNjLTRmMWItYWNlMS04ZTdmM2M0ZDU4NDEucG5n)"
      ],
      "metadata": {
        "id": "nRiiEA255TY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desafio de projeto: Tradutor de Artigos Técnicos com AzureAI"
      ],
      "metadata": {
        "id": "Rvu-S-Uc5MOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desenvolvendo uma solução de tradução de documentos e artigos utilizando o AzureAI."
      ],
      "metadata": {
        "id": "S-fj52lu6DZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalação e importação das libs necessárias"
      ],
      "metadata": {
        "id": "aTFm6lbPcDcC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClJ0ComSbwW6",
        "outputId": "b5fd08d2-4968-4582-c47b-c4a658439f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain-openai)\n",
            "  Downloading langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (0.1.137)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-openai) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-openai) (1.0.0)\n",
            "Downloading langchain_openai-0.2.5-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.15-py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.13\n",
            "    Uninstalling langchain-core-0.3.13:\n",
            "      Successfully uninstalled langchain-core-0.3.13\n",
            "Successfully installed langchain-core-0.3.15 langchain-openai-0.2.5 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4 requests python-docx  openai langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from docx import Document\n",
        "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "CwIbRPoOb9Oh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Azure Translate"
      ],
      "metadata": {
        "id": "k4z53jggcGy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = 'https://api.cognitive.microsofttranslator.com'\n",
        "subscription_key = userdata.get('AZURE_TRANSLATE_SUBSCRIPTION_KEY')\n",
        "location = 'location'\n",
        "original_language = 'en-us'\n",
        "target_language = 'pt-br'"
      ],
      "metadata": {
        "id": "B7x_OQlg6QN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_translation_request(text, from_language, original_language, endpoint):\n",
        "\n",
        "    # Definir o caminho para o endpoint de tradução.\n",
        "    path = '/translate'\n",
        "    url = endpoint + path\n",
        "\n",
        "    # Configurar os cabeçalhos necessários para autenticação e tipo de conteúdo\n",
        "    headers = {\n",
        "        'Ocp-Apim-Subscription-Key': subscription_key,   # Chave da API\n",
        "        'Ocp-Apim-Subscription-Region': location,        # Região\n",
        "        'Content-type': 'application/json',              # Tipo de conteúdo (JSON)\n",
        "        'X-ClientTraceId': str(os.urandom(16))           # Identificador único\n",
        "    }\n",
        "\n",
        "    # Corpo da solicitação, contendo o texto que será traduzido\n",
        "    body = [{'text': text}]\n",
        "\n",
        "    # Parâmetros da URL, definindo a versão da API e os idiomas de origem e destino\n",
        "    params = {\n",
        "        'api-version': '3.0',\n",
        "        'from': original_language,\n",
        "        'to': target_language\n",
        "    }\n",
        "\n",
        "    # Enviar a solicitação para o endpoint de tradução\n",
        "    request = requests.post(url, params=params, headers=headers, json=body)\n",
        "\n",
        "    # Retornar a resposta em formato JSON com o resultado da tradução\n",
        "    return request.json()\n",
        "\n",
        "\n",
        "def translate_text(text, target_language='pt-br', original_language='en'):\n",
        "    # Chama a função make_translation_request para fazer a tradução do texto\n",
        "    response = make_translation_request(text, original_language, target_language)\n",
        "\n",
        "    # Extrai e retorna o texto traduzido da resposta JSON da API\n",
        "    return response[0]['translations'][0]['text']\n",
        "\n",
        "\n",
        "def translate_document(path, target_language='pt-br', original_language='en'):\n",
        "    # Carrega o documento\n",
        "    doc = Document(path)\n",
        "    # Junta todos os parágrafos em um único texto\n",
        "    full_text = \"\\n\".join(paragraph.text for paragraph in doc.paragraphs)\n",
        "\n",
        "    # Realiza a tradução fazendo uso da função make_translation_request\n",
        "    response = make_translation_request(full_text, original_language, target_language)\n",
        "    translated_text = response[0]['translations'][0]['text']\n",
        "\n",
        "    # Cria um novo documento e adiciona o texto traduzido\n",
        "    translated_doc = Document()\n",
        "    for line in translated_text.split(\"\\n\"):\n",
        "        translated_doc.add_paragraph(line)\n",
        "\n",
        "    # Salva o documento traduzido\n",
        "    path_translated = path.replace(\".docx\", f\"_{target_language}.docx\")\n",
        "    translated_doc.save(path_translated)\n",
        "\n",
        "    return path_translated"
      ],
      "metadata": {
        "id": "g7VB5owdxzt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando o Azure Translate com uma estrofe da música Walk\n",
        "\n",
        "estrofe = \"\"\"A million miles away\n",
        "Your signal in the distance\n",
        "To whom it may concern\n",
        "I think I lost my way\n",
        "Getting good at starting over\n",
        "Every time that I return\"\"\"\n",
        "\n",
        "estrofe_traduzida = translate_text(estrofe)\n",
        "print(estrofe_traduzida)"
      ],
      "metadata": {
        "id": "Nu8QdEV1pYtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando o Azure Translate com o documento com a música Walk\n",
        "\n",
        "document_path = '/content/walk.docx'\n",
        "translated_document_path = translate_document(document_path)\n",
        "print(translated_document_path)\n",
        "\n",
        "musica = Document(translated_document_path)\n",
        "musica = \"\\n\".join(paragraph.text for paragraph in musica.paragraphs)\n",
        "print()\n",
        "print(musica)"
      ],
      "metadata": {
        "id": "JCzHzdLh8cVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Azure OpenAI"
      ],
      "metadata": {
        "id": "iHals9bKpY8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_url(url):\n",
        "    \"\"\"\n",
        "    Extrai e limpa o texto de uma página web fornecida por meio de uma URL.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Requisição GET na URL passada\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Verifica se a requisição foi bem-sucedida (código de status 200)\n",
        "    if response.status_code == 200:\n",
        "        # Pega o conteúdo da página\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Remove elementos 'script' e 'style'\n",
        "        for script_or_style in soup([\"script\", \"style\"]):\n",
        "            script_or_style.decompose()\n",
        "\n",
        "        # Extrai o texto da página, usando espaços como separador entre blocos\n",
        "        text = soup.get_text(separator=' ')\n",
        "\n",
        "        # Limpa o texto para remover espaços e linhas extras\n",
        "        lines = (line.strip() for line in text.splitlines())  # Remove espaços ao redor de cada linha\n",
        "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))  # Remove espaços internos duplos\n",
        "\n",
        "        # Reúne o texto limpo em blocos, separados por quebras de linha\n",
        "        texto_limpo = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "\n",
        "    else:\n",
        "        # Se der erro, printa o código de status HTTP\n",
        "        print(f\"Failed to fetch URL. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "    # Retorna o texto limpo extraído da página\n",
        "    return texto_limpo\n",
        "\n",
        "\n",
        "def translate_article(text, lang, client):\n",
        "    \"\"\"\n",
        "    Traduz um artigo para o idioma especificado utilizando um cliente de tradução.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Define mensagens para o cliente\n",
        "    messages = [\n",
        "        (\"system\", \"Você atua como tradutor de textos\"),\n",
        "        (\"user\", f\"Traduza o {text} para o idioma {lang} e dê a resposta no formato markdown\")\n",
        "    ]\n",
        "\n",
        "    # Envia as mensagens para o cliente e obtém a resposta com o texto traduzido\n",
        "    response = client.invoke(messages)\n",
        "\n",
        "    # Retorna o conteúdo traduzido da resposta\n",
        "    return response.content\n"
      ],
      "metadata": {
        "id": "7rroAyBD1CGC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://dev.to/modernsystemdesign/llm-for-dummies-3h90'\n",
        "\n",
        "azure_endpoint = ''\n",
        "azure_openai_api_key = userdata.get('AZURE_OPENAI_API_KEY')\n",
        "api_version = '2023-05-15'\n",
        "deployment_name = 'gpt-4o-mini'\n",
        "\n",
        "\n",
        "client = AzureChatOpenAI(\n",
        "  azure_endpoint=azure_endpoint,\n",
        "  api_key=azure_openai_api_key,\n",
        "  api_version=api_version,\n",
        "  deployment_name=deployment_name,\n",
        "  max_retries=0\n",
        ")\n",
        "\n",
        "\n",
        "text = extract_text_from_url(url)\n",
        "translated_article = translate_article(text, \"pt-br\", client)\n",
        "\n",
        "print(translated_article)"
      ],
      "metadata": {
        "id": "G37yNSEw0GeP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}