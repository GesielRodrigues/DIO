{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Bootcamp Microsoft Certification Challenge #1 - AI 102](https://assets.dio.me/79IKKjY5EHRPqlscNsYum7Iv9uQNa_siSO7Ab8Zv3II/f:webp/h:120/q:80/L3RyYWNrcy8wMzI1ZTE2Ni1mYTNjLTRmMWItYWNlMS04ZTdmM2M0ZDU4NDEucG5n)"
      ],
      "metadata": {
        "id": "nRiiEA255TY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desafio de projeto: Tradutor de Artigos Técnicos com AzureAI"
      ],
      "metadata": {
        "id": "Rvu-S-Uc5MOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desenvolvendo uma solução de tradução de documentos e artigos utilizando o AzureAI."
      ],
      "metadata": {
        "id": "S-fj52lu6DZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalação e importação das libs necessárias"
      ],
      "metadata": {
        "id": "aTFm6lbPcDcC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClJ0ComSbwW6",
        "outputId": "658e92cb-d51d-4b69-8574-280b9343c649",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain-openai)\n",
            "  Downloading langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-1.54.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (0.1.137)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-openai) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-openai) (1.0.0)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.6-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.54.1-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.3/389.3 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.15-py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx, tiktoken, openai, langchain-core, langchain-openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.52.2\n",
            "    Uninstalling openai-1.52.2:\n",
            "      Successfully uninstalled openai-1.52.2\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.13\n",
            "    Uninstalling langchain-core-0.3.13:\n",
            "      Successfully uninstalled langchain-core-0.3.13\n",
            "Successfully installed langchain-core-0.3.15 langchain-openai-0.2.6 openai-1.54.1 python-docx-1.1.2 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4 requests python-docx  openai langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from docx import Document\n",
        "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "CwIbRPoOb9Oh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Azure Translate"
      ],
      "metadata": {
        "id": "k4z53jggcGy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_translation_request(text, target_language='pt-br', original_language='en'):\n",
        "\n",
        "    # Definir o caminho para o endpoint de tradução.\n",
        "    path = '/translate'\n",
        "    url = endpoint + path\n",
        "\n",
        "    # Configurar os cabeçalhos necessários para autenticação e tipo de conteúdo\n",
        "    headers = {\n",
        "        'Ocp-Apim-Subscription-Key': subscription_key,   # Chave da API\n",
        "        'Ocp-Apim-Subscription-Region': location,        # Região\n",
        "        'Content-type': 'application/json',              # Tipo de conteúdo (JSON)\n",
        "        'X-ClientTraceId': str(os.urandom(16))           # Identificador único\n",
        "    }\n",
        "\n",
        "    # Corpo da solicitação, contendo o texto que será traduzido\n",
        "    body = [{'text': text}]\n",
        "\n",
        "    # Parâmetros da URL, definindo a versão da API e os idiomas de origem e destino\n",
        "    params = {\n",
        "        'api-version': '3.0',\n",
        "        'from': original_language,\n",
        "        'to': target_language\n",
        "    }\n",
        "\n",
        "    # Enviar a solicitação para o endpoint de tradução\n",
        "    request = requests.post(url, params=params, headers=headers, json=body)\n",
        "\n",
        "    # Retornar a resposta em formato JSON com o resultado da tradução\n",
        "    return request.json()\n",
        "\n",
        "\n",
        "def translate_text(text, target_language='pt-br', original_language='en'):\n",
        "    # Chama a função make_translation_request para fazer a tradução do texto\n",
        "    response = make_translation_request(text, target_language, original_language)\n",
        "\n",
        "    # Extrai e retorna o texto traduzido da resposta JSON da API\n",
        "    return response[0]['translations'][0]['text']\n",
        "\n",
        "\n",
        "def translate_document(path, target_language='pt-br', original_language='en'):\n",
        "    # Carrega o documento\n",
        "    doc = Document(path)\n",
        "    # Junta todos os parágrafos em um único texto\n",
        "    full_text = \"\\n\".join(paragraph.text for paragraph in doc.paragraphs)\n",
        "\n",
        "    # Realiza a tradução fazendo uso da função make_translation_request\n",
        "    response = make_translation_request(full_text, target_language, original_language)\n",
        "    translated_text = response[0]['translations'][0]['text']\n",
        "\n",
        "    # Cria um novo documento e adiciona o texto traduzido\n",
        "    translated_doc = Document()\n",
        "    for line in translated_text.split(\"\\n\"):\n",
        "        translated_doc.add_paragraph(line)\n",
        "\n",
        "    # Salva o documento traduzido\n",
        "    path_translated = path.replace(\".docx\", f\"_{target_language}.docx\")\n",
        "    translated_doc.save(path_translated)\n",
        "\n",
        "    return path_translated"
      ],
      "metadata": {
        "id": "g7VB5owdxzt-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = 'https://api.cognitive.microsofttranslator.com'\n",
        "subscription_key = userdata.get('AZURE_TRANSLATE_SUBSCRIPTION_KEY')\n",
        "location = 'eastus'\n",
        "original_language = 'en-us'\n",
        "target_language = 'pt-br'"
      ],
      "metadata": {
        "id": "B7x_OQlg6QN-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando o Azure Translate com uma estrofe da música Walk\n",
        "\n",
        "estrofe = \"\"\"A million miles away\n",
        "Your signal in the distance\n",
        "To whom it may concern\n",
        "I think I lost my way\n",
        "Getting good at starting over\n",
        "Every time that I return\"\"\"\n",
        "\n",
        "estrofe_traduzida = translate_text(estrofe)\n",
        "print(estrofe_traduzida)"
      ],
      "metadata": {
        "id": "Nu8QdEV1pYtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d384247f-6bab-47cd-ec79-a6b159c0d7e7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Um milhão de milhas de distância\n",
            "Seu sinal à distância\n",
            "A quem possa interessar\n",
            "Eu acho que perdi meu caminho\n",
            "Ficando bom em começar de novo\n",
            "Toda vez que eu voltar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando o Azure Translate com o documento com a música Walk\n",
        "\n",
        "document_path = '/content/walk.docx'\n",
        "translated_document_path = translate_document(document_path)\n",
        "print(translated_document_path)\n",
        "\n",
        "musica = Document(translated_document_path)\n",
        "musica = \"\\n\".join(paragraph.text for paragraph in musica.paragraphs)\n",
        "print()\n",
        "print(musica)"
      ],
      "metadata": {
        "id": "JCzHzdLh8cVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e503a63f-59ec-4335-8cb8-810db8787386"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/walk_pt-br.docx\n",
            "\n",
            "Um milhão de milhas de distância\n",
            "Seu sinal à distância\n",
            "A quem possa interessar\n",
            "Eu acho que perdi meu caminho\n",
            "Ficando bom em começar de novo\n",
            "Toda vez que eu voltar\n",
            "Aprendendo a andar novamente\n",
            "Eu acredito que já esperei o suficiente\n",
            "Por onde eu começo?\n",
            "Aprendendo a falar novamente\n",
            "Você não pode ver que eu esperei o suficiente?\n",
            "Por onde eu começo?\n",
            "Você se lembra dos dias?\n",
            "Nós construímos essas montanhas de papel\n",
            "Então sentou-se e assistiu-os queimar\n",
            "Eu acho que encontrei meu lugar\n",
            "Você não pode sentir isso ficando mais forte\n",
            "Pequenos conquistadores\n",
            "Aprendendo a andar novamente\n",
            "Eu acredito que já esperei o suficiente\n",
            "Por onde eu começo?\n",
            "Aprendendo a falar novamente\n",
            "Eu acredito que já esperei o suficiente\n",
            "Por onde eu começo?\n",
            "Agora\n",
            "Pela primeira vez\n",
            "Você não presta atenção\n",
            "Liberte-me, novamente\n",
            "Para se manter vivo, um momento de cada vez\n",
            "Isso ainda está dentro, um sussurro para um motim\n",
            "O sacrifício, o saber sobreviver\n",
            "Aquele primeiro declínio, outro estado de espírito\n",
            "Estou de joelhos, estou rezando por um sinal\n",
            "Para sempre, sempre, eu nunca quero morrer\n",
            "Eu nunca quero morrer\n",
            "Eu nunca quero morrer\n",
            "Eu estou de joelhos, eu nunca quero morrer\n",
            "Eu estou dançando no meu túmulo\n",
            "Eu estou correndo pelo fogo\n",
            "Para sempre, sempre que\n",
            "Eu nunca quero morrer\n",
            "Eu nunca quero sair\n",
            "Eu nunca vou dizer adeus\n",
            "Para sempre, sempre que\n",
            "Para sempre, sempre que\n",
            "Aprendendo a andar novamente\n",
            "Eu acredito que já esperei o suficiente\n",
            "Por onde eu começo?\n",
            "Aprendendo a falar novamente\n",
            "Você não pode ver que eu esperei o suficiente?\n",
            "Por onde eu começo?\n",
            "Aprendendo a andar novamente\n",
            "Eu acredito que já esperei o suficiente\n",
            "Aprendendo a falar novamente\n",
            "Você não pode ver que eu esperei o suficiente?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Azure OpenAI"
      ],
      "metadata": {
        "id": "iHals9bKpY8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_url(url):\n",
        "    \"\"\"\n",
        "    Extrai e limpa o texto de uma página web fornecida por meio de uma URL.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Requisição GET na URL passada\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Verifica se a requisição foi bem-sucedida (código de status 200)\n",
        "    if response.status_code == 200:\n",
        "        # Pega o conteúdo da página\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Pegando apenas o conteúdo do post (buscando pelo id da div)\n",
        "        content = soup.find(id=\"main-content\")\n",
        "\n",
        "        # Remove elementos 'script' e 'style'\n",
        "        for script_or_style in content([\"script\", \"style\"]):\n",
        "            script_or_style.decompose()\n",
        "\n",
        "        # Extrai o texto da página, usando espaços como separador entre blocos\n",
        "        text = content.get_text(separator=' ')\n",
        "\n",
        "        # Limpa o texto para remover espaços e linhas extras\n",
        "        lines = (line.strip() for line in text.splitlines())  # Remove espaços ao redor de cada linha\n",
        "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))  # Remove espaços internos duplos\n",
        "\n",
        "        # Reúne o texto limpo em blocos, separados por quebras de linha\n",
        "        texto_limpo = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "\n",
        "    else:\n",
        "        # Se der erro, printa o código de status HTTP\n",
        "        print(f\"Failed to fetch URL. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "    # Retorna o texto limpo extraído da página\n",
        "    return texto_limpo\n",
        "\n",
        "\n",
        "def translate_article(text, lang, client):\n",
        "    \"\"\"\n",
        "    Traduz um artigo para o idioma especificado utilizando um cliente de tradução.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Define mensagens para o cliente\n",
        "    messages = [\n",
        "        (\"system\", \"Você atua como tradutor de textos\"),\n",
        "        (\"user\", f\"Traduza o {text} para o idioma {lang} e dê a resposta no formato markdown\")\n",
        "    ]\n",
        "\n",
        "    # Envia as mensagens para o cliente e obtém a resposta com o texto traduzido\n",
        "    response = client.invoke(messages)\n",
        "\n",
        "    # Retorna o conteúdo traduzido da resposta\n",
        "    return response.content\n"
      ],
      "metadata": {
        "id": "7rroAyBD1CGC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "azure_endpoint = 'https://gesiel-oai-eastus-001.openai.azure.com/'\n",
        "azure_openai_api_key = userdata.get('AZURE_OPENAI_API_KEY')\n",
        "api_version = '2024-08-01-preview'\n",
        "deployment_name = 'gpt-4o'\n",
        "\n",
        "\n",
        "client = AzureChatOpenAI(\n",
        "  azure_endpoint=azure_endpoint,\n",
        "  api_key=azure_openai_api_key,\n",
        "  api_version=api_version,\n",
        "  deployment_name=deployment_name,\n",
        "  max_retries=0\n",
        ")"
      ],
      "metadata": {
        "id": "jGavycLh4uyQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando com uma estrofe da música Walk\n",
        "\n",
        "text = \"\"\"A million miles away\n",
        "Your signal in the distance\n",
        "To whom it may concern\n",
        "I think I lost my way\n",
        "Getting good at starting over\n",
        "Every time that I return\"\"\"\n",
        "\n",
        "translated_text = translate_article(text, \"pt-br\", client)\n",
        "\n",
        "print(translated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gytSW-SS2AWu",
        "outputId": "f3ed8bd7-8e10-40ea-e3dc-a2c2261a8578"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```markdown\n",
            "A um milhão de milhas de distância\n",
            "Seu sinal na distância\n",
            "A quem possa interessar\n",
            "Acho que perdi meu caminho\n",
            "Ficando bom em recomeçar\n",
            "Toda vez que eu retorno\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando com um artigo, limitando os caracteres para não estourar o limite de tokens\n",
        "url = 'https://dev.to/modernsystemdesign/llm-for-dummies-3h90'\n",
        "text = extract_text_from_url(url)[:800]\n",
        "\n",
        "translated_article = translate_article(text, \"pt-br\", client)\n",
        "print(translated_article)"
      ],
      "metadata": {
        "id": "G37yNSEw0GeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37b94e95-2e49-4835-e85a-4c07656545fe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nrapesh Khamesra  \n",
            "Publicado em  \n",
            "19 de mar. de 2023  \n",
            "LLM para iniciantes  \n",
            "#llm  \n",
            "#chatgpt  \n",
            "#gpt3  \n",
            "\n",
            "Nos últimos anos, houve um avanço significativo no processamento de linguagem natural, levando ao desenvolvimento de grandes modelos de linguagem (LLMs). Esses modelos tornaram-se cada vez mais populares devido à sua capacidade de processar e gerar linguagem semelhante à humana. Este artigo tem como objetivo explicar os LLMs para um novato, abordando tópicos como seu funcionamento, suas aplicações e seus potenciais benefícios e desvantagens.\n",
            "\n",
            "## O que são Grandes Modelos de Linguagem?\n",
            "\n",
            "LLMs são programas de computador que utilizam técnicas de inteligência artificial para processar e gerar linguagem natural. Eles são projetados para entender e gerar uma linguagem semelhante à humana e são construídos usando algoritmos de aprendizado profundo. Esses modelos são treinados em grandes conjuntos de dados de texto, permitindo-lhes reconhecer padrões e gerar respostas coerentes e contextualmente relevantes.\n",
            "\n",
            "Por exemplo, o GPT-3 (Generative Pre-trained Transformer 3) é um dos LLMs mais avançados disponíveis atualmente. Ele pode realizar uma variedade de tarefas de processamento de linguagem natural, como tradução de idiomas, resumo de texto, resposta a perguntas e até mesmo criação de conteúdo criativo.\n",
            "\n",
            "## Como funcionam os LLMs?\n",
            "\n",
            "Os LLMs utilizam redes neurais profundas, que são compostas por várias camadas de neurônios artificiais. Essas redes são treinadas em grandes volumes de dados de texto, permitindo que aprendam padrões e relacionamentos dentro da linguagem. Durante o treinamento, os modelos ajustam seus pesos e vieses para melhorar a precisão de suas previsões.\n",
            "\n",
            "O processo de treinamento envolve a exposição do modelo a uma grande quantidade de texto, onde ele tenta prever a próxima palavra em uma sequência. Com o tempo, o modelo ajusta seus parâmetros com base no erro de suas previsões, refinando sua capacidade de gerar linguagem coerente.\n",
            "\n",
            "## Aplicações dos LLMs\n",
            "\n",
            "Os LLMs têm uma ampla gama de aplicações em várias indústrias e setores. Alguns exemplos incluem:\n",
            "\n",
            "- **Assistentes virtuais:** LLMs são usados em assistentes virtuais como Siri, Alexa e Google Assistant para entender e responder a comandos de voz.\n",
            "- **Tradução de idiomas:** Modelos como o GPT-3 podem traduzir texto de um idioma para outro, facilitando a comunicação global.\n",
            "- **Geração de conteúdo:** LLMs podem criar artigos, histórias, poemas e outros tipos de conteúdo escrito.\n",
            "- **Análise de sentimentos:** Empresas utilizam LLMs para analisar o sentimento em redes sociais e feedback de clientes.\n",
            "- **Chatbots:** LLMs são usados para desenvolver chatbots que podem interagir com os clientes de maneira natural e eficaz.\n",
            "\n",
            "## Benefícios e Desvantagens dos LLMs\n",
            "\n",
            "### Benefícios:\n",
            "\n",
            "- **Precisão:** LLMs podem gerar respostas precisas e contextualmente relevantes.\n",
            "- **Versatilidade:** Eles podem ser aplicados em uma ampla variedade de tarefas de processamento de linguagem natural.\n",
            "- **Eficiência:** LLMs podem processar grandes volumes de texto rapidamente.\n",
            "\n",
            "### Desvantagens:\n",
            "\n",
            "- **Custo:** O treinamento de LLMs requer recursos computacionais significativos, tornando-o caro.\n",
            "- **Enviesamento:** LLMs podem refletir vieses presentes nos dados de treinamento, levando a respostas tendenciosas.\n",
            "- **Complexidade:** A interpretação e explicação dos resultados gerados por LLMs podem ser difíceis devido à complexidade dos modelos.\n",
            "\n",
            "Em resumo, os grandes modelos de linguagem representam um avanço significativo no campo do processamento de linguagem natural, com inúmeras aplicações e benefícios. No entanto, também é importante estar ciente das suas limitações e desafios ao utilizá-los.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9jIm_6VzQjfe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}